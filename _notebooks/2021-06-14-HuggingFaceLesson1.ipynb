{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HuggingFace Course Notes, Chapter 1 (And Zero), Part 1\n",
    "\n",
    "> This notebook covers all of Chapter 0, and Chapter 1 up to \"How do Transformers Work?\"\n",
    "\n",
    "- toc: true\n",
    "- badges: true\n",
    "- comments: true\n",
    "- image: images/hugging-face.png\n",
    "- category: HuggingFace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 0 (Setup):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since HF in of itself has no dependancy requirements, they recommend us installing `transformers[dev]` so it gets all the dev requirements for \"any imaginable use case\".\n",
    "\n",
    "A full list of what it installs is below:\n",
    "\n",
    "```\n",
    "deps = {\n",
    "    \"Pillow\": \"Pillow\",\n",
    "    \"black\": \"black==21.4b0\",\n",
    "    \"cookiecutter\": \"cookiecutter==1.7.2\",\n",
    "    \"dataclasses\": \"dataclasses\",\n",
    "    \"datasets\": \"datasets\",\n",
    "    \"deepspeed\": \"deepspeed>=0.4.0\",\n",
    "    \"docutils\": \"docutils==0.16.0\",\n",
    "    \"fairscale\": \"fairscale>0.3\",\n",
    "    \"faiss-cpu\": \"faiss-cpu\",\n",
    "    \"fastapi\": \"fastapi\",\n",
    "    \"filelock\": \"filelock\",\n",
    "    \"flake8\": \"flake8>=3.8.3\",\n",
    "    \"flax\": \"flax>=0.3.4\",\n",
    "    \"fugashi\": \"fugashi>=1.0\",\n",
    "    \"huggingface-hub\": \"huggingface-hub==0.0.8\",\n",
    "    \"importlib_metadata\": \"importlib_metadata\",\n",
    "    \"ipadic\": \"ipadic>=1.0.0,<2.0\",\n",
    "    \"isort\": \"isort>=5.5.4\",\n",
    "    \"jax\": \"jax>=0.2.8\",\n",
    "    \"jaxlib\": \"jaxlib>=0.1.65\",\n",
    "    \"jieba\": \"jieba\",\n",
    "    \"keras2onnx\": \"keras2onnx\",\n",
    "    \"nltk\": \"nltk\",\n",
    "    \"numpy\": \"numpy>=1.17\",\n",
    "    \"onnxconverter-common\": \"onnxconverter-common\",\n",
    "    \"onnxruntime-tools\": \"onnxruntime-tools>=1.4.2\",\n",
    "    \"onnxruntime\": \"onnxruntime>=1.4.0\",\n",
    "    \"optuna\": \"optuna\",\n",
    "    \"packaging\": \"packaging\",\n",
    "    \"parameterized\": \"parameterized\",\n",
    "    \"protobuf\": \"protobuf\",\n",
    "    \"psutil\": \"psutil\",\n",
    "    \"pydantic\": \"pydantic\",\n",
    "    \"pytest\": \"pytest\",\n",
    "    \"pytest-sugar\": \"pytest-sugar\",\n",
    "    \"pytest-xdist\": \"pytest-xdist\",\n",
    "    \"python\": \"python>=3.6.0\",\n",
    "    \"ray\": \"ray\",\n",
    "    \"recommonmark\": \"recommonmark\",\n",
    "    \"regex\": \"regex!=2019.12.17\",\n",
    "    \"requests\": \"requests\",\n",
    "    \"rouge-score\": \"rouge-score\",\n",
    "    \"sacrebleu\": \"sacrebleu>=1.4.12\",\n",
    "    \"sacremoses\": \"sacremoses\",\n",
    "    \"sagemaker\": \"sagemaker>=2.31.0\",\n",
    "    \"scikit-learn\": \"scikit-learn\",\n",
    "    \"sentencepiece\": \"sentencepiece==0.1.91\",\n",
    "    \"soundfile\": \"soundfile\",\n",
    "    \"sphinx-copybutton\": \"sphinx-copybutton\",\n",
    "    \"sphinx-markdown-tables\": \"sphinx-markdown-tables\",\n",
    "    \"sphinx-rtd-theme\": \"sphinx-rtd-theme==0.4.3\",\n",
    "    \"sphinx\": \"sphinx==3.2.1\",\n",
    "    \"sphinxext-opengraph\": \"sphinxext-opengraph==0.4.1\",\n",
    "    \"starlette\": \"starlette\",\n",
    "    \"tensorflow-cpu\": \"tensorflow-cpu>=2.3\",\n",
    "    \"tensorflow\": \"tensorflow>=2.3\",\n",
    "    \"timeout-decorator\": \"timeout-decorator\",\n",
    "    \"timm\": \"timm\",\n",
    "    \"tokenizers\": \"tokenizers>=0.10.1,<0.11\",\n",
    "    \"torch\": \"torch>=1.0\",\n",
    "    \"torchaudio\": \"torchaudio\",\n",
    "    \"tqdm\": \"tqdm>=4.27\",\n",
    "    \"unidic\": \"unidic>=1.0.2\",\n",
    "    \"unidic_lite\": \"unidic_lite>=1.0.7\",\n",
    "    \"uvicorn\": \"uvicorn\",\n",
    "}\n",
    "```\n",
    "\n",
    "> Note: after exploring a bit I found their requirements are located [here](https://github.com/huggingface/transformers/blob/master/src/transformers/dependency_versions_table.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: pytest-forked 1.3.0 has requirement pytest>=3.10, but you'll have pytest 3.6.4 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: pytest-xdist 2.2.1 has requirement pytest>=6.0.0, but you'll have pytest 3.6.4 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: black 21.4b0 has requirement regex>=2020.1.8, but you'll have regex 2019.12.20 which is incompatible.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers[dev] -U >> /dev/null # Ensure we upgrade and clean the output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should take a bit to run. I noticed four incompatibility errors in Colab, we'll see if it has any issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: transformers\n",
      "Version: 4.6.1\n",
      "Summary: State-of-the-art Natural Language Processing for TensorFlow 2.0 and PyTorch\n",
      "Home-page: https://github.com/huggingface/transformers\n",
      "Author: Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Sam Shleifer, Patrick von Platen, Sylvain Gugger, Suraj Patil, Stas Bekman, Google AI Language Team Authors, Open AI team Authors, Facebook AI Authors, Carnegie Mellon University Authors\n",
      "Author-email: thomas@huggingface.co\n",
      "License: Apache\n",
      "Location: /usr/local/lib/python3.7/dist-packages\n",
      "Requires: tokenizers, packaging, importlib-metadata, numpy, filelock, tqdm, requests, huggingface-hub, sacremoses, regex\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright! We can move onto Chapter 1! ðŸ¤—"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "Looks as though it's split into three main chunks:\n",
    "\n",
    "- Introduction\n",
    "- Diving in\n",
    "- Advanced\n",
    "\n",
    "Introduction will show a very surface level with Transformers models and HF Transformers, fine-tuning a basic model, and sharing models and tokenizers.\n",
    "\n",
    "Diving in will go further into the HF datasets and tokenizers library, basic NLP tasks, and how to ask for help (presumably on the forums or on Twitter?)\n",
    "\n",
    "Advanced looks to be covering specialized architecture, speeding up training, custom training loops (yay!) and contributing to HF itself.\n",
    "\n",
    "> Note: This is better taken after an intro course such as Practical Deep Learning for Coders or any course developed by deeplearning.ai.\n",
    "\n",
    "It also mentions that they don't expect any prior PyTorch or Tensorflow knowledge, but some familiarity will help. (fastai likely helps here too some)\n",
    "\n",
    "The wonderful authors: \n",
    "\n",
    "- Matthew Carrigan - MLE @ HF\n",
    "- Lysandre Debut - MLE @ HF, worked with Transformers library from the very beginning\n",
    "- Sylvain Gugger - Research Engineer @ HF, core maintainer of Transformers. And one of our favorite former fastai folk\n",
    "\n",
    "**What we will learn**:\n",
    "\n",
    "- The `pipeline` function\n",
    "- The Transformer architecture\n",
    "- Encoder, decoder, and encoder/decoder architectures and when to use each"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Natural Language Processing\n",
    "\n",
    "- What is it?\n",
    "\n",
    "Classifying whole sentences or each word in a sentence, generating text content, question answering, and generating a new sentence from an input text\n",
    "\n",
    "- Why is it challenging?\n",
    "\n",
    "For a human, given \"I am hungry\" and \"I am sad\" we can know how similar thye are. That's hard for ML models. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformers, what can they do?\n",
    "\n",
    "We get to look at `pipeline` now!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [Model Hub](https://huggingface.co/models) is a super valuable resource because it contains thousands of pretrained models for you to use, and you can upload your own. *The* language model zoo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Working with Pipelines, with Sylvain](https://youtu.be/tiZFewofSLM)\n",
    "\n",
    "> Offhand note, I like that the videos are broken up into ~4-5 minute chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General approach to how I will take these notes:\n",
    "\n",
    "1. Watch video without notes\n",
    "2. Read the website and take notes\n",
    "3. Go back to the video and catch anything I missed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pipeline` is a very quick and powerful way to grab inference with any HF model.\n",
    "\n",
    "Let's break down one example below they showed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa66cc7675ed4f88b62142cb9991ecae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=629.0, style=ProgressStyle(description_â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddca15486a09483db278d785b2094a48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=267844284.0, style=ProgressStyle(descriâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "def49a2de3a548a4b631f2a774ad1865",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descriptiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce5ace6e0f4442c5b41073c8b0b5003d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=48.0, style=ProgressStyle(description_wâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9943008422851562}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "classifier(\"I've been waiting for a HuggingFace course all my life!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What did this do here?\n",
    "\n",
    "1. Downloaded a model (judging by the download bar). Don't know which model yet is the default\n",
    "2. I *think* we downloaded a pretrained tokenizer too?\n",
    "3. Said model was the default for a `sentiment-analysis` task\n",
    "4. We asked it to classify the sentiment in our sentence. Labels are positive and negative, and it gave us back an array of dictionaries with those values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also pass in multiple inputs/texts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9598048329353333},\n",
       " {'label': 'NEGATIVE', 'score': 0.9994558095932007}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier([\n",
    "    \"I've been waiting for a HuggingFace course my whole life.\", \n",
    "    \"I hate this so much!\"\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default model for this task is a pretrained model fine-uned for sentient analysis in english. Let's see if I can't find it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__abstractmethods__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_forward',\n",
       " '_parse_and_tokenize',\n",
       " 'binary_output',\n",
       " 'check_model_type',\n",
       " 'default_input_names',\n",
       " 'device',\n",
       " 'device_placement',\n",
       " 'ensure_tensor_on_device',\n",
       " 'feature_extractor',\n",
       " 'framework',\n",
       " 'model',\n",
       " 'modelcard',\n",
       " 'predict',\n",
       " 'return_all_scores',\n",
       " 'save_pretrained',\n",
       " 'task',\n",
       " 'tokenizer',\n",
       " 'transform']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pt'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.models.distilbert.modeling_distilbert.DistilBertForSequenceClassification"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(classifier.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it's a `DistilBertForSequenceClassification`, likely using the default which would be `en-sentiment`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Current available pipeline classes:\n",
    "* `feature-extraction` (vector representation of a text)\n",
    "* `fill-mask`\n",
    "* `ner` (Named-Entity-Recognition)\n",
    "* `question-answering`\n",
    "* `sentiment-analysis`\n",
    "* `text-generation`\n",
    "* `translation`\n",
    "* `zero-shot-classification`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero-Shot Classification\n",
    "\n",
    "- Classifying unlabelled tasks. \n",
    "\n",
    "`zero-shot-classification` pipeline let's us specify which labels to use for classification, even if they may differ from the pretrained models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Side Note: I'm going to write a quick namespace class via `mk_class` in fastcore to hold all of these tasks, so I can get tab-completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install fastcore >> /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.basics import mk_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_dict = {'FeatureExtraction':'feature-extraction',\n",
    " 'FillMask':'fill-mask',\n",
    " 'NER':'ner',\n",
    " 'QuestionAnswering':'question-answering',\n",
    " 'SentimentAnalysis':'sentiment-analysis',\n",
    " 'Summarization':'summarization',\n",
    " 'TextGeneration':'text-generation',\n",
    " 'Translation':'translation',\n",
    " 'ZeroShotClassification':'zero-shot-classification'\n",
    " }\n",
    "\n",
    "mk_class('Task', **cls_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'feature-extraction'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Task.FeatureExtraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see all I've done is load a fancy namespace-like object from `fastcore` that holds my dictionary values as attributes instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to the HF stuff. Let's load in a pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline(Task.ZeroShotClassification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems this model took quite a bit longer to download, but our `Task` object is working great!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': ['education', 'business', 'politics'],\n",
       " 'scores': [0.844597339630127, 0.11197540909051895, 0.043427303433418274],\n",
       " 'sequence': 'This is a course about the Transformers library'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\n",
    "    \"This is a course about the Transformers library\",\n",
    "    candidate_labels=['education','politics','business']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very interesting, so we can see right away it could tell this was educational! (Or fit the closest to that label.) I wonder how it works under the hood, something I may peruse later. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Generation\n",
    "\n",
    "Generate some fancy text given a prompt.\n",
    "\n",
    "Similar to predictive text feature on my iPhone.\n",
    "\n",
    "Has some randomness, so we won't 100% get the smae thing each time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b974a9a49b9404d9761326f99240ce6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=665.0, style=ProgressStyle(description_â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "751e6a77d8474800865267f1a44d1038",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=548118077.0, style=ProgressStyle(descriâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "283b30d4abe14a8bab29ebbcb5b99e1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1042301.0, style=ProgressStyle(descriptâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1271320533134e01b8fe5df2671a1f6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descriptiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b25c0b0d602445e183c5e011983ed924",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1355256.0, style=ProgressStyle(descriptâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "generator = pipeline(Task.TextGeneration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'In this course we will teach you how to create a custom project with custom options.\\n\\nBefore you begin, you will also want to check how to setup the build system. It is available in all versions, at all times we recommend using the'}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\"In this course we will teach you how to\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Theres a few args we can control and pass to it, such as `num_return_sequences` and `max_length`.\n",
    "\n",
    "The homework is to try and generate two sentences of 15 words each. Let's try that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'In Marine Biology, the study was published in Physical Review Letters.\\n\\n'},\n",
       " {'generated_text': \"In Marine Biology, a graduate of California's Stanford University, said the discovery\"}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\n",
    "    \"In Marine Biology,\",\n",
    "    num_return_sequences=2,\n",
    "    max_length=15\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool! Easy to use\n",
    "\n",
    "A headache I ran into is it's `num_return_sequences`, **not** `num_returned_sequences`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use any model from the Hub in a pipeline\n",
    "\n",
    "I **love** the HuggingFace hub, so very happy to see this in here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models can be found on the [ModelHub](https://huggingface.co/models). In this example we use distilgpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb8c3bd021484ceb8ac2e2c8b7b777eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=762.0, style=ProgressStyle(description_â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea0ec5377bf94eca8584abf2f98ba69d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=352833716.0, style=ProgressStyle(descriâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f63ef796ebb45318a901f0ee11a2df6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1042301.0, style=ProgressStyle(descriptâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d625d1c0ee942df8f3fe516a3dbf3bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descriptiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5013e3e3912c413bb3c0179c0b509cca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1355256.0, style=ProgressStyle(descriptâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'In this course, we will teach you how to integrate a Python function into your application and use a Python object. In addition, we will be teaching'},\n",
       " {'generated_text': 'In this course, we will teach you how to set up your own private cloud. Our class begins with our server and takes you through a variety of'}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = pipeline(Task.TextGeneration, model='distilgpt2')\n",
    "\n",
    "generator(\n",
    "    \"In this course, we will teach you how to\",\n",
    "    max_length=30,\n",
    "    num_return_sequences=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mask Filling\n",
    "\n",
    "Fill in the blanks of a given text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdd267c14db84f59975707cb858774c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=480.0, style=ProgressStyle(description_â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39c26443b2bb4cd78fb5f2fb413c634b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=331070498.0, style=ProgressStyle(descriâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "142213c4bdb842828285ce25d8727734",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898823.0, style=ProgressStyle(descriptiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "178b40cce36440c3a4af5086b709b19a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descriptiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1635790693664b23b88a33bf98afd0a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1355863.0, style=ProgressStyle(descriptâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "unmasker = pipeline(Task.FillMask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.19619838893413544,\n",
       "  'sequence': 'This course will teach you all about mathematical models.',\n",
       "  'token': 30412,\n",
       "  'token_str': ' mathematical'},\n",
       " {'score': 0.040527306497097015,\n",
       "  'sequence': 'This course will teach you all about computational models.',\n",
       "  'token': 38163,\n",
       "  'token_str': ' computational'}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker('This course will teach you all about <mask> models.', top_k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So here it thought the best word to fill that with was mathematical, followed by computational (and showed the filled in sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`top_k` is how many possibilities are displayed\n",
    "\n",
    "> Note: Model fills `<mask>`, and different models will have different things it will try and fill that with. One way to check this is by looking at the mask word used in the widget (on HF ModelHub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Named Entity Recognition (NER)\n",
    "\n",
    "Find parts of an input text that correspond to entities such as persons, locations, or organizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner = pipeline(Task.NER, grouped_entities=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'end': 23,\n",
       "  'entity_group': 'PER',\n",
       "  'score': 0.9987525741259257,\n",
       "  'start': 11,\n",
       "  'word': 'Zach Mueller'},\n",
       " {'end': 55,\n",
       "  'entity_group': 'LOC',\n",
       "  'score': 0.9819004138310751,\n",
       "  'start': 46,\n",
       "  'word': 'Pensacola'}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner(\"My name is Zach Mueller and I go to school in Pensacola\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does having it not grouped do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'end': 15,\n",
       "  'entity': 'I-PER',\n",
       "  'index': 4,\n",
       "  'score': 0.9993382692337036,\n",
       "  'start': 11,\n",
       "  'word': 'Zach'},\n",
       " {'end': 18,\n",
       "  'entity': 'I-PER',\n",
       "  'index': 5,\n",
       "  'score': 0.999767005443573,\n",
       "  'start': 16,\n",
       "  'word': 'Mu'},\n",
       " {'end': 23,\n",
       "  'entity': 'I-PER',\n",
       "  'index': 6,\n",
       "  'score': 0.9971524477005005,\n",
       "  'start': 18,\n",
       "  'word': '##eller'},\n",
       " {'end': 49,\n",
       "  'entity': 'I-LOC',\n",
       "  'index': 13,\n",
       "  'score': 0.9945659637451172,\n",
       "  'start': 46,\n",
       "  'word': 'Pen'},\n",
       " {'end': 51,\n",
       "  'entity': 'I-LOC',\n",
       "  'index': 14,\n",
       "  'score': 0.956141471862793,\n",
       "  'start': 49,\n",
       "  'word': '##sa'},\n",
       " {'end': 55,\n",
       "  'entity': 'I-LOC',\n",
       "  'index': 15,\n",
       "  'score': 0.9949938058853149,\n",
       "  'start': 51,\n",
       "  'word': '##cola'}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner = pipeline(Task.NER, grouped_entities=False)\n",
    "ner(\"My name is Zach Mueller and I go to school in Pensacola\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can see that the first grouped \"Zach\" and \"Mueller\" together as a single item, and Pen, Sa, Cola together too (likely split with the subword tokenizer). Having `grouped=True` sounds like a good default in this case\n",
    "\n",
    "Most models that you want to have aligned with this task have some form of `POS` abbriviation in the name or tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question Answering (QA)\n",
    "\n",
    "This is very straightforward, query a question and then receive an answer given some context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': 'Pensacola', 'end': 55, 'score': 0.9609196186065674, 'start': 46}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa = pipeline(Task.QuestionAnswering)\n",
    "qa(\n",
    "    question=\"Where do I work?\",\n",
    "    context=\"My name is Zach Mueller and I go to school in Pensacola\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: this is an **extraction** method, *not* text generation. So it just _extracted_ Pensacola from the question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reduce a text to a shorter one, while keeping most of the important aspects referenced in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbfdfdaec3684df9a50189c16519e7a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1802.0, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcb0cb3d07df483d810532329828c9b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1222317369.0, style=ProgressStyle(descrâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6926154b88404b02ad39a5be592d5533",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898822.0, style=ProgressStyle(descriptiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd75ce31e56b454e974ea203f4f59450",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descriptiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aafb17d14ec04d93bcfdcf6b58876478",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=26.0, style=ProgressStyle(description_wâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "summarizer = pipeline(Task.Summarization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': ' America has changed dramatically during recent years . The number of engineering graduates in the U.S. has declined in traditional engineering disciplines such as mechanical, civil,    electrical, chemical, and aeronautical engineering . Rapidly developing economies such as China and India continue to encourage and advance the teaching of engineering .'}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer(\"\"\"\n",
    "    America has changed dramatically during recent years. Not only has the number of \n",
    "    graduates in traditional engineering disciplines such as mechanical, civil, \n",
    "    electrical, chemical, and aeronautical engineering declined, but in most of \n",
    "    the premier American universities engineering curricula now concentrate on \n",
    "    and encourage largely the study of engineering science. As a result, there \n",
    "    are declining offerings in engineering subjects dealing with infrastructure, \n",
    "    the environment, and related issues, and greater concentration on high \n",
    "    technology subjects, largely supporting increasingly complex scientific \n",
    "    developments. While the latter is important, it should not be at the expense \n",
    "    of more traditional engineering.\n",
    "\n",
    "    Rapidly developing economies such as China and India, as well as other \n",
    "    industrial countries in Europe and Asia, continue to encourage and advance \n",
    "    the teaching of engineering. Both China and India, respectively, graduate \n",
    "    six and eight times as many traditional engineers as does the United States. \n",
    "    Other industrial countries at minimum maintain their output, while America \n",
    "    suffers an increasingly serious decline in the number of engineering graduates \n",
    "    and a lack of well-educated engineers.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translation\n",
    "\n",
    "The last task in the tutorial/lesson is machine translation. Usually the model name will have some `lang1_to_lang2` naming convention in the title. The easiest way to pick one is to search on the model hub. In this example we'll translate French to english (let's see how much I remember from my French classes in high school!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f38afb9558c74f7c90c8075812c1dfdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1132.0, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab4557454c34426ba78ad57f46892b7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=300827685.0, style=ProgressStyle(descriâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc82db94ac7449d0b727f24932a3c1d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=802397.0, style=ProgressStyle(descriptiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04a9e0fbeb8e4a4ba3616d5901668a77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=778395.0, style=ProgressStyle(descriptiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5b1c063c25449d29be02922344ec970",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1339166.0, style=ProgressStyle(descriptâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8759c33550c43dfa0ba4b2914ef7595",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=42.0, style=ProgressStyle(description_wâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "translator = pipeline(Task.Translation, model='Helsinki-NLP/opus-mt-fr-en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation_text': \"I'm Zach, what's your name?\"}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator(\"Je m'apelle Zach, comment-vous est appelez-vous?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also specify a `max_lenght` or `min_length` for the generated result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next chapter, we'll learn what is inside a pipeline and customizing its behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
